{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from edward.models import Normal\n",
    "from edward.models import Bernoulli\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "\"\"\"\n",
    "Helper methods\n",
    "\"\"\"\n",
    "##creates a weight variable with name and shape\n",
    "def _weight_variable(name, shape):\n",
    "    w = tf.get_variable(name, shape, tf.float32, tf.truncated_normal_initializer(stddev=0.1))\n",
    "    tf.add_to_collection('vars',w)\n",
    "    return w\n",
    "\n",
    "\n",
    "def _bias_variable(name, shape):\n",
    "    b = tf.get_variable(name, shape,tf.float32, tf.constant_initializer(0.1, dtype=tf.float32))\n",
    "    tf.add_to_collection('vars',b)\n",
    "    return b\n",
    "\n",
    "def _get3d_deconv_output_size(input_height, input_width,input_depth, filter_height,\n",
    "                             filter_width,filter_depth, row_stride, col_stride,depth_stride,\n",
    "                             padding_type):\n",
    "    \"\"\"Returns the number of rows and columns in a convolution/pooling output.\n",
    "    \"\"\"\n",
    "    input_height = tensor_shape.as_dimension(input_height)\n",
    "    input_width = tensor_shape.as_dimension(input_width)\n",
    "    input_depth = tensor_shape.as_dimension(input_depth)\n",
    "    filter_height = tensor_shape.as_dimension(filter_height)\n",
    "    filter_width = tensor_shape.as_dimension(filter_width)\n",
    "    filter_depth = tensor_shape.as_dimension(filter_depth)\n",
    "    row_stride = int(row_stride)\n",
    "    col_stride = int(col_stride)\n",
    "    depth_stride = int(depth_stride)\n",
    "\n",
    "    # Compute number of rows in the output, based on the padding.\n",
    "    if input_height.value is None or filter_height.value is None:\n",
    "        out_rows = None\n",
    "    elif padding_type == \"VALID\":\n",
    "        out_rows = (input_height.value - 1) * row_stride + filter_height.value\n",
    "    elif padding_type == \"SAME\":\n",
    "        out_rows = input_height.value * row_stride\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for padding: %r\" % padding_type)\n",
    "\n",
    "    # Compute number of columns in the output, based on the padding.\n",
    "    if input_width.value is None or filter_width.value is None:\n",
    "        out_cols = None\n",
    "    elif padding_type == \"VALID\":\n",
    "        out_cols = (input_width.value - 1) * col_stride + filter_width.value\n",
    "    elif padding_type == \"SAME\":\n",
    "        out_cols = input_width.value * col_stride\n",
    "        \n",
    "    # Compute number of columns in the output, based on the padding.\n",
    "    if input_depth.value is None or filter_depth.value is None:\n",
    "        out_depth = None\n",
    "    elif padding_type == \"VALID\":\n",
    "        out_depth = (input_depth.value - 1) * depth_stride + filter_depth.value\n",
    "    elif padding_type == \"SAME\":\n",
    "        out_depth = input_depth.value * depth_stride\n",
    "\n",
    "\n",
    "    return out_rows, out_cols,out_depth\n",
    "\n",
    "\n",
    "## creates a deconvolution layer with specific activation function\n",
    "def _3D_deconv_layer(name, kernel_shape, biases_shape,prev_layer, activation_fn = tf.nn.relu,\n",
    "                  strides = [1, 1, 1,1,1], padding = 'VALID'):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        kernel = _weight_variable('weights',kernel_shape)\n",
    "        biases = _bias_variable('biases',biases_shape)\n",
    "        \n",
    "        out_row,out_col,out_depth = _get3d_deconv_output_size(prev_layer.shape[1],prev_layer.shape[2],prev_layer.shape[3],kernel_shape[0],kernel_shape[1],kernel_shape[2],strides[1],strides[2],strides[3],padding)\n",
    "        output_shape = [batch_size,out_row,out_col,out_depth,kernel_shape[3]]\n",
    "        conv = tf.nn.conv3d_transpose(prev_layer,kernel,output_shape, strides,padding=padding,name=scope.name)\n",
    "        conv = tf.nn.bias_add(conv,biases)\n",
    "        if activation_fn is not None:\n",
    "            conv = activation_fn(conv)\n",
    "    return conv\n",
    "\n",
    "##creates a convolution layer with specific activation function\n",
    "def _3D_conv_layer(name, kernel_shape, biases_shape,prev_layer, activation_fn = tf.nn.relu,\n",
    "                  strides = [1, 1, 1, 1, 1], padding = 'VALID'):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        kernel = _weight_variable('weights',kernel_shape)\n",
    "        biases = _bias_variable('biases',biases_shape)\n",
    "        conv = tf.nn.conv3d(prev_layer,kernel,strides,padding=padding)\n",
    "        conv = tf.nn.bias_add(conv,biases)\n",
    "        if activation_fn is not None:\n",
    "            conv = activation_fn(conv,name = scope.name)\n",
    "    return conv\n",
    "\n",
    "\n",
    "# we take a random variable z~N(0,1)\n",
    "# pass through deconvolutional network\n",
    "# to produce a mean and sigma for each voxel\n",
    "def generative_network(z):\n",
    "    \"\"\"Generative network to parameterize the generative model\n",
    "    It takes latent variables as input and outputs the likelihood parameters\n",
    "        \n",
    "    mu = neural_network(z) sigma = neural_network(z)\n",
    "    \"\"\"\n",
    "    reshape_z = tf.reshape(z,[batch_size,1,1,1,latent_dimension])\n",
    "    prev_layer = reshape_z\n",
    "    in_filter = latent_dimension\n",
    "    #deconv layer 1\n",
    "    out_filter=20\n",
    "    kernel_shape = [3,3,3,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_deconv_layer('deconv1',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "\n",
    "    #deconv layer 2\n",
    "    out_filter=10\n",
    "    kernel_shape = [4,5,4,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_deconv_layer('deconv2',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "\n",
    "    #deconv layer 3\n",
    "    out_filter=5\n",
    "    kernel_shape = [5,5,5,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_deconv_layer('deconv3',kernel_shape,biases_shape,prev_layer,strides = [1,2,2,2,1])\n",
    "    in_filter = out_filter\n",
    "    #deconv layer 4\n",
    "    out_filter=1\n",
    "    kernel_shape = [3,3,3,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_deconv_layer('deconv4',kernel_shape,biases_shape,prev_layer,strides = [1,2,2,2,1],padding = 'SAME')\n",
    "    in_filter = out_filter\n",
    "    \"\"\"\n",
    "    #deconv layer 5\n",
    "    out_filter=3\n",
    "    kernel_shape = [5,7,5,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_deconv_layer('deconv5',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "   \n",
    "    #deconv layer 6\n",
    "    out_filter = 12\n",
    "    kernel_shape  =[10,10,10,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_deconv_layer('deconv6',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "    \"\"\"\n",
    "    #fully connected layer\n",
    "    dim = tensor_shape.as_dimension(prev_layer.shape[1])*tensor_shape.as_dimension(prev_layer.shape[2])*tensor_shape.as_dimension(prev_layer.shape[3])*tensor_shape.as_dimension(prev_layer.shape[4])\n",
    "    dim = int(dim)\n",
    "    prev_layer_flat = tf.reshape(prev_layer, [batch_size, dim])\n",
    "\n",
    "    weights = _weight_variable('weights_full_gen', [dim, x_shape[0]*x_shape[1]*x_shape[2]])\n",
    "    biases = _bias_variable('biases_full_gen', [x_shape[0]*x_shape[1]*x_shape[2]])\n",
    "    fully_connected = tf.nn.sigmoid(tf.matmul(prev_layer_flat, weights) + biases)\n",
    "    \"\"\"\n",
    "    #output_layer\n",
    "    mu = tf.reshape(fully_connected[:, :latent_dimension],[batch_size,latent_dimension])\n",
    "    out_filter = 1\n",
    "    kernel_shape = [2,4,2,out_filter,in_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    output = _3D_deconv_layer('gen_output',kernel_shape,biases_shape,prev_layer,activation_fn=tf.nn.sigmoid)\n",
    "    \"\"\"\n",
    "    mu = tf.reshape(fully_connected,[batch_size,x_shape[0],x_shape[1],x_shape[2],1])\n",
    "    #sigma =  tf.reshape(tf.nn.softplus(output[:,:,:,:,1]),[batch_size,x_shape[0],x_shape[1],x_shape[2],1]) + 1e-10\n",
    "\n",
    "    return mu#,sigma\n",
    "\n",
    "def inference_network(x,latent_dimension = 100):\n",
    "    \"\"\"Inference network to parameterize the variational family\n",
    "    it takes data as input and outputs the variational parameters\n",
    "    \n",
    "    \n",
    "    the network follows the architecture given by \n",
    "    Deep MRI brain extraction: A 3D convolutional neural network for\n",
    "skull stripping Kleesiek, J 2016\n",
    "\n",
    "    mu,sigma = encoder_neural_network(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    latent_dimension = latent_dimension\n",
    "    in_filter = 1\n",
    "    #reshaped_x = tf.reshape(x,[batch_size,tf.shape(x)[1],tf.shape(x)[2],tf.shape(x)[3],in_filter])\n",
    "    #layer 1\n",
    "    out_filter = 16\n",
    "    kernel_shape = [4,4,4,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv1',kernel_shape,biases_shape,x)\n",
    "    in_filter = out_filter\n",
    "    \n",
    "    #do max pooling\n",
    "    pool1 = tf.nn.max_pool3d(prev_layer,ksize = [1,2,2,2,1],\n",
    "                             strides = [1,2,2,2,1],\n",
    "                            padding= 'SAME')\n",
    "    \n",
    "    prev_layer = pool1\n",
    "    \n",
    "    #layer 2\n",
    "    out_filter = 24\n",
    "    kernel_shape = [5,5,5,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv2',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "    \n",
    "    \n",
    "    #layer 3\n",
    "    out_filter = 28\n",
    "    kernel_shape = [4,4,4,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv3',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "    \n",
    "    #layer 4\n",
    "    out_filter = 5\n",
    "    kernel_shape = [4,4,4,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv4',kernel_shape,biases_shape,prev_layer,strides = [1,2,2,2,1])\n",
    "    in_filter = out_filter\n",
    "    \"\"\"\n",
    "    #layer 5\n",
    "    out_filter = 2\n",
    "    kernel_shape = [5,5,5,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv5',kernel_shape,biases_shape,prev_layer,activation_fn=None)\n",
    "    in_filter = out_filter\n",
    "    #layer 6\n",
    "    out_filter = 50\n",
    "    kernel_shape = [5,5,5,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv6',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "    \n",
    "    #layer 7\n",
    "    out_filter = 50\n",
    "    kernel_shape = [5,5,5,in_filter,out_filter]\n",
    "    biases_shape = [out_filter]\n",
    "    prev_layer = _3D_conv_layer('conv7',kernel_shape,biases_shape,prev_layer)\n",
    "    in_filter = out_filter\n",
    "    \"\"\"\n",
    "    \n",
    "    #fully connected layer\n",
    "    dim = tensor_shape.as_dimension(prev_layer.shape[1])*tensor_shape.as_dimension(prev_layer.shape[2])*tensor_shape.as_dimension(prev_layer.shape[3])*tensor_shape.as_dimension(prev_layer.shape[4])\n",
    "    dim = int(dim)\n",
    "    prev_layer_flat = tf.reshape(prev_layer, [batch_size, dim])\n",
    "\n",
    "    weights = _weight_variable('weights_full', [dim, latent_dimension*2])\n",
    "    biases = _bias_variable('biases_full', [latent_dimension*2])\n",
    "    fully_connected = tf.matmul(prev_layer_flat, weights) + biases\n",
    "    \n",
    "    mu = tf.reshape(fully_connected[:, :latent_dimension],[batch_size,latent_dimension])\n",
    "    sigma = tf.reshape(tf.nn.softplus(fully_connected[:,latent_dimension:]),[batch_size,latent_dimension]) + 1e-10\n",
    "    \"\"\"\n",
    "    fully_connected = prev_layer\n",
    "    mu = tf.reshape(fully_connected[:,:,:,:,0],[batch_size,latent_dimesnion])\n",
    "    signa = tf.reshape(tf.nn.softplus(fully_connected[:,:,:,:,1]),[batch_size,latent_dimension])+1e-10\n",
    "    \"\"\"\n",
    "    return mu,sigma\n",
    "\n",
    "def read_and_decode_single_example(filename):\n",
    "    # first construct a queue containing a list of filenames.\n",
    "    # this lets a user split up there dataset in multiple files to keep\n",
    "    # size down\n",
    "    filename_queue = tf.train.string_input_producer([filename],\n",
    "                                                    num_epochs=None)\n",
    "    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\n",
    "    reader = tf.TFRecordReader()\n",
    "    # One can read a single serialized example from a filename\n",
    "    # serialized_example is a Tensor of type string.\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # The serialized example is converted back to actual values.\n",
    "    # One needs to describe the format of the objects to be returned\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            # We know the length of both fields. If not the\n",
    "            # tf.VarLenFeature could be used\n",
    "            'image': tf.FixedLenFeature([x_shape[0]*x_shape[1]*x_shape[2]], tf.float32)\n",
    "        })\n",
    "    # now return the converted data\n",
    "    image = features['image']\n",
    "    return image\n",
    "\"\"\"\n",
    " Global variables\n",
    "\"\"\"\n",
    "ed.set_seed(42)\n",
    "latent_dimension = 100\n",
    "batch_size = 4\n",
    "#x_shape = [91,109,91]\n",
    "x_shape = [31,37,31]\n",
    "\n",
    "\"\"\"\n",
    "The model\n",
    "\"\"\"\n",
    "z = Normal(mu = tf.zeros([batch_size,latent_dimension]), sigma = tf.ones([batch_size,latent_dimension]))\n",
    "#mu_x,sigma_x = generative_network(z)\n",
    "mu_x = generative_network(z)\n",
    "#x = Normal(mu = mu_x,sigma = sigma_x)\n",
    "x = Bernoulli(logits = mu_x)\n",
    "##inference\n",
    "x_ph = tf.placeholder(tf.float32, [batch_size, x_shape[0],x_shape[1],x_shape[2],1])\n",
    "mu, sigma = inference_network(x_ph)\n",
    "#we use mean field approximation\n",
    "qz = Normal(mu=mu, sigma=sigma)\n",
    "\n",
    "# Bind p(x, z) and q(z | x) to the same placeholder for x.\n",
    "data = {x: x_ph}\n",
    "inference = ed.KLqp({z: qz},data)\n",
    "optimizer = tf.train.AdamOptimizer(0.01, epsilon=1.0)\n",
    "inference.initialize(optimizer=optimizer)\n",
    "## IMPORt the data\n",
    "\n",
    "# returns symbolic label and image\n",
    "image = read_and_decode_single_example(\"T1_mri_normalized.tfrecords\")\n",
    "# groups examples into batches randomly\n",
    "images_batch = tf.train.shuffle_batch(\n",
    "    [image], batch_size=batch_size,\n",
    "    capacity=20,\n",
    "    min_after_dequeue=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Lets train the model!\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=session,coord=coord)\n",
    "    n_epoch = 4\n",
    "    n_iter_per_epoch = int(32/batch_size)\n",
    "    for epoch in range(n_epoch):\n",
    "        avg_loss = 0.0\n",
    "        for t in range(n_iter_per_epoch):\n",
    "            x_train= session.run([images_batch])[0]\n",
    "            x_train = np.reshape(x_train,(batch_size,x_shape[0],x_shape[1],x_shape[2],1))\n",
    "            info_dict = inference.update(feed_dict={x_ph: x_train})\n",
    "            avg_loss += info_dict['loss']\n",
    "\n",
    "            # Print a lower bound to the average marginal likelihood for an\n",
    "            # image.\n",
    "        avg_loss = avg_loss / n_iter_per_epoch\n",
    "        avg_loss = avg_loss / batch_size\n",
    "        print(\"log p(x) >= {:0.3f}\".format(avg_loss))\n",
    "\n",
    "        saver.save(session,'/home/harrison/Documents/mri_vae/mri_vae_model/my-model.ckpt',write_meta_graph=True,global_step = epoch)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    x_train= session.run([images_batch])[0]\n",
    "    x_train = np.reshape(x_train,(batch_size,x_shape[0],x_shape[1],x_shape[2],1))\n",
    "    reconstruct_x = session.run(mu_x, feed_dict = {x_ph:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session =tf.Session()\n",
    "saver.restore(session, '/home/harrison/Documents/mri_vae/mri_vae_model/my-model.ckpt-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruct_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(reconstruct_x[0,:,:,10,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruct_x[0,:,:,15,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.rot90(x_train[0,:,:,10,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
